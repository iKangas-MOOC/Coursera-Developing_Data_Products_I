yfit <- dnorm(xfit, mean=1/lambda, sd=(1/lambda/sqrt(sample_size)))
lines(xfit, yfit, pch=22, col="red", lty=2)
# add legend
legend('topright', c("simulation", "theoretical"), lty=c(1,2), col=c("black", "red"))
nosim <- 1000
mns = NULL
for (i in 1 : nosim) mns = c(mns, mean(runif(40)))
row_means<-mns
hist(row_means, breaks=50, prob=TRUE,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
# density of the averages of samples
lines(density(row_means))
# theoretical center of distribution
abline(v=1/lambda, col="red")
# theoretical density of the averages of samples
xfit <- seq(min(row_means), max(row_means), length=100)
yfit <- dnorm(xfit, mean=1/lambda, sd=(1/lambda/sqrt(sample_size)))
yfit
nosim <- 1000
mns = NULL
for (i in 1 : nosim) mns = c(mns, mean(runif(40)))
row_means<-mns
hist(row_means, breaks=50, prob=TRUE,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
# density of the averages of samples
lines(density(row_means))
# theoretical center of distribution
abline(v=1/lambda, col="red")
nosim <- 1000
mns = NULL
for (i in 1 : nosim) mns = c(mns, mean(runif(40)))
row_means<-mns
hist(row_means, breaks=50, prob=TRUE,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
# density of the averages of samples
lines(density(row_means))
# theoretical center of distribution
abline(v=0.51, col="red")
nosim <- 1000
mns = NULL
for (i in 1 : nosim) mns = c(mns, mean(runif(40)))
row_means<-mns
hist(row_means, breaks=50, prob=TRUE,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
# density of the averages of samples
lines(density(row_means))
# theoretical center of distribution
abline(v=0.51, col="red")
# theoretical density of the averages of samples
xfit <- seq(min(row_means), max(row_means), length=100)
yfit <- dnorm(xfit, mean=0.51, sd=(0.51/sqrt(sample_size)))
lines(xfit, yfit, pch=22, col="red", lty=2)
# add legend
legend('topright', c("simulation", "theoretical"), lty=c(1,2), col=c("black", "red"))
nosim <- 1000
mns = NULL
for (i in 1 : nosim) mns = c(mns, mean(runif(40)))
hist(mns, breaks=50, prob=TRUE,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
# density of the averages of samples
lines(density(mns))
# theoretical center of distribution
abline(v=0.51, col="red")
# theoretical density of the averages of samples
xfit <- seq(min(mns), max(mns), length=100)
yfit <- dnorm(xfit, mean=0.51, sd=(0.51/sqrt(sample_size)))
lines(xfit, yfit, pch=22, col="red", lty=2)
# add legend
legend('topright', c("simulation", "theoretical"), lty=c(1,2), col=c("black", "red"))
nosim <- 1000
mns = NULL
for (i in 1 : nosim) mns = c(mns, mean(rnorm(40)))
hist(mns, breaks=50, prob=TRUE,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
# density of the averages of samples
lines(density(mns))
# theoretical center of distribution
abline(v=0.51, col="red")
# theoretical density of the averages of samples
xfit <- seq(min(mns), max(mns), length=100)
yfit <- dnorm(xfit, mean=0.51, sd=(0.51/sqrt(sample_size)))
lines(xfit, yfit, pch=22, col="red", lty=2)
# add legend
legend('topright', c("simulation", "theoretical"), lty=c(1,2), col=c("black", "red"))
a<- ToothGrowth
a
View(a)
summary(a)
?ToothGrowth
table(a$supp,a$dose)
table(a$supp,a$dose,a$len)
table(a$supp,a$len,a$dose)
hist(a$len)
pnorm(1.38)
1-pnorm(1.38)
1.96*1.38
77+c(-1,1)*2.7048
81.25-77
4.25*6
25.5/1.96
sampl<-c(180,200,190,230,80,160,170,130,140,220,110,120,100,170)
mean(sampl)
48.5/sqrt(14)
1.96*48.5/sqrt(14.5)
1.96*48.5/sqrt(14)
mean(sampl)+c(-1,1)*1.96*48.5/sqrt(14)
surv <- read.csv("C:/Users/kioannis/Downloads/StudentSurvey.csv")
View(surv)
sum(surv[1:10,'name_letters']>10)
sum(surv[1:10,'name_letters']>5)
sum(surv[1:10,'name_letters']>3)
surv[surv$happy<40,'name_letters']
surv[surv$happy<40,'name_letters'][1]
survey<-surv
# Calculate the population parameters
hist(survey$name_letters)
fivenum(survey$name_letters)
mean(survey$name_letters)
sd(survey$name_letters)
# Draw 1,000 samples of n=5 and find the mean of each sample.
xbar5 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$name_letters, size =5)
xbar5[i] <-  mean(x)}
# Graph the histogram of 1,000 sample means.
hist(xbar5,xlim=c(2,10))
# Calculate the mean and sd of the sampling distribution.
mean(xbar5)
sd(xbar5)
# Compare to the std dev predicted by the CTL.
sd(survey$name_letters)/sqrt(5)
#Repeat for samples of size n=15
xbar15 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$name_letters, size =15)
xbar15[i] <- mean(x)}
hist(xbar15,xlim=c(2,10))
mean(xbar15)
sd(xbar15)
sd(survey$name_letters)/sqrt(15)
#Repeat for samples of size n=25
xbar25 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$name_letters, size =25)
xbar25[i] <- mean(x)}
hist(xbar25,xlim=c(2,10))
mean(xbar25)
sd(xbar25)
sd(survey$name_letters)/sqrt(25)
hist(survey$name_letters)
hist(survey$happy)
mean(survey$happy)
sd(survey$happy)
fivenum(survey$happy)
# Draw 1,000 samples of n=5 and find the mean of each sample.
xbar5 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$happy, size =5)
xbar5[i] <-  mean(x)}
# Graph the histogram of 1,000 sample means.
hist(xbar5,xlim=c(2,10))
# Calculate the mean and sd of the sampling distribution.
mean(xbar5)
sd(xbar5)
# Compare to the std dev predicted by the CTL.
sd(survey$happy)/sqrt(5)
#Repeat for samples of size n=15
xbar15 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$happy, size =15)
xbar15[i] <- mean(x)}
hist(xbar15,xlim=c(2,10))
mean(xbar15)
sd(xbar15)
sd(survey$happy)/sqrt(15)
#Repeat for samples of size n=25
xbar25 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$happy, size =25)
xbar25[i] <- mean(x)}
hist(xbar25,xlim=c(2,10))
mean(xbar25)
sd(xbar25)
sd(survey$happy)/sqrt(25)
xbar5 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$happy, size =5)
xbar5[i] <-  mean(x)}
xbar5 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$happy, size =5)
xbar5[i] <-  mean(x)}
hist(xbar5,xlim=c(0,100))
# Draw 1,000 samples of n=5 and find the mean of each sample.
xbar5 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$happy, size =5)
xbar5[i] <-  mean(x)}
# Graph the histogram of 1,000 sample means.
hist(xbar5,xlim=c(0,100))
# Calculate the mean and sd of the sampling distribution.
mean(xbar5)
sd(xbar5)
# Compare to the std dev predicted by the CTL.
sd(survey$happy)/sqrt(5)
#Repeat for samples of size n=15
xbar15 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$happy, size =15)
xbar15[i] <- mean(x)}
hist(xbar15,xlim=c(0,100))
mean(xbar15)
sd(xbar15)
sd(survey$happy)/sqrt(15)
#Repeat for samples of size n=25
xbar25 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$happy, size =25)
xbar25[i] <- mean(x)}
hist(xbar25,xlim=c(0,100))
mean(xbar25)
sd(xbar25)
sd(survey$happy)/sqrt(25)
survey<-surv
# Calculate the population parameters
hist(survey$happy)
fivenum(survey$happy)
mean(survey$happy)
sd(survey$happy)
# Draw 1,000 samples of n=5 and find the mean of each sample.
xbar5 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$happy, size =5)
xbar5[i] <-  mean(x)}
# Graph the histogram of 1,000 sample means.
hist(xbar5,xlim=c(0,100))
# Calculate the mean and sd of the sampling distribution.
mean(xbar5)
sd(xbar5)
# Compare to the std dev predicted by the CTL.
sd(survey$happy)/sqrt(5)
#Repeat for samples of size n=15
xbar15 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$happy, size =15)
xbar15[i] <- mean(x)}
hist(xbar15,xlim=c(0,100))
mean(xbar15)
sd(xbar15)
sd(survey$happy)/sqrt(15)
#Repeat for samples of size n=25
xbar25 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$happy, size =25)
xbar25[i] <- mean(x)}
hist(xbar25,xlim=c(0,100))
mean(xbar25)
sd(xbar25)
sd(survey$happy)/sqrt(25)
hist(survey$happy)
hist(survey$austin)
mean(survey$austin)
sd(survey$austin)
1.51/sqrt(10)
pnorm(q = 3.2, mean = 3.08, sd = 0.4,lower.tail = false)
pnorm(q = 3.2, mean = 3.08, sd = 0.4,lower.tail = F)
pnorm(q = 3.2, mean = 3.08, sd = 0.4)
pnorm(q = 3.2, mean = 3.08, sd = 0.08,lower.tail = F)
pnorm(q = 2.9, mean = 3.08, sd = 0.08)
pnorm(q = 3.2, mean = 3.08, sd = 0.08)
pnorm(q = 3.2, mean = 3.08, sd = 0.08)-pnorm(q = 2.9, mean = 3.08, sd = 0.08)
11/sqrt(23)
(35.1-28)/11
(35.1-28)/2.29
pnorm(35.1,28,2.2936)
1-pnorm(35.1,28,2.2936)
1.5/sqrt(15)
1.96*1.5/sqrt(15)
471.46+c(-1,1)*0.7591047
install.packages(caret)
install.packages("caret")
library(caret)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages('AppliedPredictiveModeling')
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
adData1 = data.frame(predictors)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(Hmisc)
?cut2
plot(training$CompressiveStrength)
View(training)
library(ggplot)
library(ggplot2)
qplot(training$CompressiveStrength,colours=Water)
qplot(training$CompressiveStrength,colour=Water)
qplot(CompressiveStrength,colour=Water,data=training)
qplot(CompressiveStrength,colour=cut2(Water),data=training)
qplot(CompressiveStrength,index,colour=cut2(Water),data=training)
?plot
?qplot
qplot(CompressiveStrength,cut2(Water),data=training)
qplot(CompressiveStrength,Water,data=training)
qplot(CompressiveStrength,FlyAsh,data=training)
qplot(CompressiveStrength,cut2(FlyAsh),data=training)
qplot(CompressiveStrength,cut2(Age),data=training)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
q3 <- log(training$Superplasticizer)
hist(q3)
log(0)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
names(training)[1:2]=='IL'
sapply(names(training),function(x){x[1:2]=='IL'})
lapply(names(training),function(x){x[1:2]=='IL'})
names(training)[1]
names(training)=='IL'
names(training)=='IL*'
names(training)[,1:2]=='IL*'
names(training)[,][1:2]=='IL*'
names(training)[1]
names(training)[1][1:3]
str(names(training)[1])
str(names(training)[1])[1:3]
names(training)>'IL'
names(training)<>'IL'
names(training)><'IL'
names(training)>'IL' & names(training)<'IL'
?grep
grepl(pattern = '^IL',x = names(training))
st<-grepl(pattern = '^IL',x = names(training))
sum(st)
newd <- training[,st]
head(mewd)
head(newd)
View(numdata1)
View(training)
hod="pca",pcaComp=6)
trainPC <- predict(preProc,newd)
preProc <- preProess(newd,method="pca",pcaComp=6)
trainPC <- predict(preProc,newd)
preProc <- preProcess(newd,method="pca",pcaComp=6)
trainPC <- predict(preProc,newd)
trainPC
confusionMatrix(data = trainPC)
preProc <- preProcess(newd,method="pca",pcaComp=6)
trainPC <- predict(preProc,newd)
modelFit <- train(training$diagnosis ~ ., method='glm',data=trainPC)
tnewd <- testing[,grepl(pattern = '^IL',x = names(testing))]
testPC <- predict(preProc,tnewd)
confusionMatrix(testing$diagnosis, predict(modelFit, testPC))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
newd <- training[,grepl(pattern = '^IL',x = names(training))]
preProc <- preProcess(newd,method="pca",pcaComp=6)
trainPC <- predict(preProc,newd)
modelFit <- train(training$diagnosis ~ .,method='glm',data=trainPC)
install.packages('e1071')
library(e1071)
modelFit <- train(training$diagnosis ~ .,method='glm',data=trainPC)
tnewd <- testing[,grepl(pattern = '^IL',x = names(testing))]
testPC <- predict(preProc,tnewd)
confusionMatrix(testing$diagnosis, predict(modelFit, testPC))
newd <- training[,grepl(pattern = '^IL',x = names(training))]
preProc <- preProcess(newd,method="pca",pcaComp=7)
trainPC <- predict(preProc,newd)
modelFit <- train(training$diagnosis ~ .,method='glm',data=trainPC)
tnewd <- testing[,grepl(pattern = '^IL',x = names(testing))]
testPC <- predict(preProc,tnewd)
confusionMatrix(testing$diagnosis, predict(modelFit, testPC))
newd <- training[,grepl(pattern = '^IL',x = names(training))]
preProc <- preProcess(newd,method="pca",pcaComp=8)
trainPC <- predict(preProc,newd)
modelFit <- train(training$diagnosis ~ .,method='glm',data=trainPC)
tnewd <- testing[,grepl(pattern = '^IL',x = names(testing))]
testPC <- predict(preProc,tnewd)
confusionMatrix(testing$diagnosis, predict(modelFit, testPC))
preProc <- preProcess(newd,method="pca",pcaComp=12)
newd <- training[,grepl(pattern = '^IL',x = names(training))]
preProc <- preProcess(newd,method="pca",pcaComp=12)
trainPC <- predict(preProc,newd)
modelFit <- train(training$diagnosis ~ .,method='glm',data=trainPC)
tnewd <- testing[,grepl(pattern = '^IL',x = names(testing))]
testPC <- predict(preProc,tnewd)
confusionMatrix(testing$diagnosis, predict(modelFit, testPC))
newd <- training[,grepl(pattern = '^IL',x = names(training))]
preProc <- preProcess(newd,method="pca",pcaComp=12)
preProc$rotation
newd <- training[,grepl(pattern = '^IL',x = names(training))]
preProc <- preProcess(newd,method="pca",thresh=12)
preProc$rotation
newd <- training[,grepl(pattern = '^IL',x = names(training))]
preProc <- preProcess(newd,method="pca",thresh=0.8)
preProc$rotation
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
newd <- training[,grepl(pattern = '^IL',x = names(training))]
newd
dim(newd)
preProc1 <- preProcess(newd,method="pca",thresh = 0.8)
preProc1$rotation
preProc <- preProcess(newd,method="pca",pcaComp=7)
trainPC <- predict(preProc,newd)
modelFit <- train(training$diagnosis ~ .,method='glm',data=trainPC)
tnewd <- testing[,grepl(pattern = '^IL',x = names(testing))]
testPC <- predict(preProc,tnewd)
confusionMatrix(testing$diagnosis, predict(modelFit, testPC))
head(training[,-diagnosis])
head(training[,-2])
head(training[,c(1,3,-2])
head(training[,c(1,3,-2)])
head(training[,-1])
modelFit1 <- train(training$diagnosis ~ .,method='glm',data=newd])
modelFit1 <- train(training$diagnosis ~ .,method='glm',data=newd)
newd <- training[,grepl(pattern = '^IL',x = names(training))]
preProc1 <- preProcess(newd,method="pca",thresh = 1)
preProc1$rotation
trainPC
modelFit <- train(training$diagnosis ~ .,method='glm',data=newd)
tnewd <- testing[,grepl(pattern = '^IL',x = names(testing))]
confusionMatrix(testing$diagnosis, ~ .,method='glm',data=tnewd)
confusionMatrix(testing$diagnosis~ .,method='glm',data=tnewd)
confusionMatrix(testing$diagnosis, predict(modelFit, tnewd))
2000-1891/(251/20)
(2000-1891)/(251/20)
(2000-1891)/(251/24)
(2000-1891)/(251/sqrt(24))
(2000-1891)/sqrt(251/24)
(2000-1891)/(251/sqrt(25))
861/sqrt(7)
59/sqrt(7)
(891-900)/22.2999
(861-900)/22.2999
(78-66)/sqrt(((12.56^2)/10)+((12.04^2)/15))
pt(0.95,9)
qt(0.95,9)
qt(0.95,3)
(5184-((5184+7921+8836+4761)/4))/8836
(5184-((5184+7921+8836+4761)/4))/(8836-4761)
(94-((89+72+94+69)/4))/(94-69)
21111+6900-14161
60/96
57/60
19/0.625
1-(1-0.05)**6
library(Rtools)
library('Rtools')
install.packages('Rtools')
library(shiny)
install.packages('shiny')
library(shiny)
library(devtools)
setwd("C:/Users/kioannis/Desktop/Rplay/DevelopingDataProducts")
runApp()
?mean
?lm
?colSums
?dgamma
?show
